% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mjolnir4_ODIN.R
\name{mjolnir4_ODIN}
\alias{mjolnir4_ODIN}
\title{ODIN: OTU Delimitation Inferred by Networks}
\usage{
mjolnir4_ODIN(
  lib,
  cores,
  d = 13,
  min_reads_MOTU = 2,
  min_reads_ESV = 2,
  alpha = 5,
  entropy = c(0.47, 0.23, 1.02, 313),
  algorithm = "DnoisE_SWARM",
  obipath = "",
  python_packages = "",
  swarmpath = NULL,
  dnoise_path = NULL,
  remove_singletons = TRUE,
  remove_DMS = T
)
}
\arguments{
\item{lib}{Character string. Acronym for the experiment. This
acronym must be of 4 characters in capital letters. Do not mix up library and
experiment acronyms. However they can be the same.}

\item{cores}{Numeric. Number of threads for parallel processing.}

\item{d}{Numeric value for d parameter of SWARM that refers to the maximum 
number of differences between two sequences to be linked in the same cluster}

\item{min_reads_MOTU}{Numeric. Minimum number of reads that a MOTU needs to 
have to be retained.}

\item{min_reads_ESV}{Numeric. Minimum number of reads that an ESV needs to 
have to be retained.}

\item{alpha}{Numeric. Alpha value for DnoisE to run.}

\item{entropy}{Logical, numeric or character vector specifying whether to run
DnoisE with entropy correction and how. 

a) c(0.47,0.23,1.02,313) - formulation refers to the entropy values for the 
first, second and third position in the codon and the length of the main 
sequence length expected. See Antich et al. 2022 for further details.

b) FALSE - this will disable the entropy correction. Recommended for non 
coding markers

c) c("auto_sample",313) - this will compute the entropy values for 313 
(plus or minus multiple of 3) bp within DnoisE and use them to perform the entropy correction

d) c("auto_dataset") - this will compute the entropy values for all the 
dataset and all sequence lengths and use the main sequence length's values for 
the entropy correction}

\item{algorithm}{Character. It specifies the algorithm to obtain MOTUs and/or ESVs. Ther are four options:

a)"DnoisE_SWARM" - This option will run DnoisE before SWARM. This option is the best 
choice for highly diverse data sets so it will reduce the computation time of 
SWARM. It also allows the analysis of metaphylogeographical approaches and 
retrieves denoised and quality filter fasta files for each sample that can 
be used for other experiment without previous run of RAN, FREYJA and HELA. It
will result on a table of MOTUs and the ESV clustered into them.

b)"SWARM" - This option will run only SWARM to obtain a MOTU table.

c)"SWARM_DnoisE" - This option will run SWARM before DnoisE. This option 
responds to a philosophical point of view where the denoising of the 
sequences have to be performed within MOTUs so closer sequences are compared 
and to avoid that high abundant sequences from different MOTUs absorb 
sequences (and thus their reads) from different MOTUs. However, there are no major 
differences between this option and the "DnoisE_SWARM" option. It allows the 
analysis of metaphylogeographical and will result on a table of MOTUs and 
the ESV clustered into them.

d)"DnoisE" - This option will run only DnoisE. This option will retrieve 
quality filter fasta files for each sample that can 
be used for other experiment without previous run of RAN, FREYJA and HELA.}

\item{obipath}{Character string specifying the PATH to the obi binary.}

\item{python_packages}{Character string specifying the PATH to where the 
Python3 packages are stored.}

\item{swarmpath}{Character string specifying the PATH to the SWARM program.}

\item{dnoise_path}{Character string specifying the PATH to the DnoisE program.}

\item{remove_singletons}{Logical. If TRUE this will remove the sequences that,
after dereplication when joining all samples (those will be denoised for when 
algorithm="DnoisE_SWARM" or algorithm="DnoisE"), have only one read.}

\item{remove_DMS}{Logical. If TRUE, it will delete all obidms objects that are
created during the process. This can save a lot of hard disk space. The FALSE 
option is useful for developing and debugging.}
}
\description{
ODIN performs MOTU clustering and/or denoising. It is one of the main steps of MJOLNIR.
}
\details{
The function mjolnir4_ODIN() uses the four different strategies to delimit 
MOTUs and/or ESVs. This strategies are set with the algorithm parameter: 
a)"DnoisE_SWARM", b)"SWARM", c)"SWARM_DnoisE" and d)"DnoisE". 

In short, DnoisE refers to the denoising process with DnoisE to obtain ESV 
and SWARM to a clustering process with SWARM to obtain MOTUs. DnoisE is a 
software to merge spurious sequences into their "mothers" (see Antich et al. 
2022) to obtain Exact (also Amplicon) Sequence variants. DnoisE is an open 
source and parallelizable alternative to Unoise that allows to introduce an 
entropy correction based on the different entropies of each position in the 
codon of coding genes. This is highly recommended for markers as COI for 
which this program was intended. However, with the entropy=FALSE parameter, 
this programs performs the same denoising procedure as described for Unoise3. 
SWARM is an algorithm to delimit MOTUs, based on linkage-networks created by 
step-by-step agregation. This clustering algorithm is not based on an 
arbitrary, constant, absolute identity threshold. Conversely, SWARM is based 
on an iterative aggregation of sequences that differ less than a given 
distance d. This strategy results into linkage-networks of different sizes, 
which can have different effective values for within-MOTU identity threshold, 
depending on the complexity of the natural variability of the sequences 
present in the sample. This procedure is very convenient in the case of 
hypervariable metabarcoding markers, such as COI, which usually feature 
extremely high levels of natural diversity, in addition to the random sequencing errors.
Dereplication step takes place after joining all samples into the same file 
before SWARM in algorithms a, b and c and after DnoisE in algorithms a and d
}
\examples{
library(mjolnir)

# Define input fastq files (only names of R1 files are needed)
R1_filenames <-c("ULO1_R1.fastq.gz","ULO2_R1.fastq.gz","ULO3_R1.fastq.gz","ULO4_R1.fastq.gz")

# Input identifiers for the individual libraries to be used. It should be a 4-character name, matching the information in the ngsfilter files
lib_prefixes <- c("ULO1","ULO2","ULO3","ULO4")

# Enter number of cores to be used in parallel. 
cores <- 7

# Run RAN
mjolnir1_RAN(R1_filenames,cores,lib_prefixes,R1_motif="_R1",R2_motif="_R2")

# set experiment acronym
lib <- "ULOY"

# Run FREYJA
mjolnir2_FREYJA(lib_prefix = lib_prefixes,lib = lib,cores = cores,Lmin=299,Lmax=320)

# set the maximum number of cores possible
cores <- 16

# Run HELA
mjolnir3_HELA(lib,cores)

# Run ODIN
mjolnir4_ODIN(lib,cores,d=13,min_reads_MOTU=2,min_reads_ESV=2,alpha=5,entropy=c(0.47,0.23,1.02,313), algorithm="DnoisE_SWARM", remove_singletons = TRUE)
}
